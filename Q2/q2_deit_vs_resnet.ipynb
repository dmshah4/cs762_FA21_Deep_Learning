{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q2-deit_vs_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d60e0c975ea4b5f9fc977ecf37762ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_562776ececa94061b51183ae5ae50e26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7c656b918f34dca8c8cb544da80c79a",
              "IPY_MODEL_6c584ede18a44f94986a4a7c9d6420af",
              "IPY_MODEL_bef72ca4abbf4ffdba83b22e417dd15a"
            ]
          }
        },
        "562776ececa94061b51183ae5ae50e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7c656b918f34dca8c8cb544da80c79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff266179d74d4cc2944eabcca4232c9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38d569a318714852a19bf8bea3aeefe1"
          }
        },
        "6c584ede18a44f94986a4a7c9d6420af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ec78162b14a3472ea9b0cfc9772dbad1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4470285b0b747b5999ae2234acf98df"
          }
        },
        "bef72ca4abbf4ffdba83b22e417dd15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6345f865d54f4b1bac285b4317f8ad74",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 66.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9bbeaf078ee43d6b63b2335d33843e3"
          }
        },
        "ff266179d74d4cc2944eabcca4232c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38d569a318714852a19bf8bea3aeefe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec78162b14a3472ea9b0cfc9772dbad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4470285b0b747b5999ae2234acf98df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6345f865d54f4b1bac285b4317f8ad74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9bbeaf078ee43d6b63b2335d33843e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d1ca7ed135d4e3fa993ac140aa52f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e92092e78bcf45fb8a6044ffb8436ac4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4931863fbdd9470db32a29993e05dd79",
              "IPY_MODEL_13ca5b9820ff4b1aa224fbe160eb733e",
              "IPY_MODEL_3e39b810b4d14c3282c68e498eeddeb4"
            ]
          }
        },
        "e92092e78bcf45fb8a6044ffb8436ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4931863fbdd9470db32a29993e05dd79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdf6986108524cf49ac993ec4108a4ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60d0ffe1a69b41b2a35d5b7d7b0e779a"
          }
        },
        "13ca5b9820ff4b1aa224fbe160eb733e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9837af3a2382477aa7de75d615bf7acd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 22917895,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 22917895,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac90275949ab4f8f97fe77289c58c469"
          }
        },
        "3e39b810b4d14c3282c68e498eeddeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf5c777282284a49923fb5edafbc71cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 21.9M/21.9M [00:01&lt;00:00, 20.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87ae01f200594fcba55abb1ca083d5bd"
          }
        },
        "cdf6986108524cf49ac993ec4108a4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60d0ffe1a69b41b2a35d5b7d7b0e779a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9837af3a2382477aa7de75d615bf7acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac90275949ab4f8f97fe77289c58c469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf5c777282284a49923fb5edafbc71cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87ae01f200594fcba55abb1ca083d5bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zzzudyubDoT",
        "outputId": "8faae191-8d7c-4f02-b93f-5d1e02da10b7"
      },
      "source": [
        "# !pip install grad-cam\n",
        "!pip install ttach\n",
        "!pip install timm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n",
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAN7HyEFDpR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c587c5-01fb-46d5-932f-e4487102b572"
      },
      "source": [
        "!git clone https://github.com/vigneshuw/pytorch-grad-cam.git\n",
        "!pip install pytorch-grad-cam/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-grad-cam'...\n",
            "remote: Enumerating objects: 702, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 702 (delta 155), reused 129 (delta 129), pack-reused 501\u001b[K\n",
            "Receiving objects: 100% (702/702), 1.89 MiB | 21.02 MiB/s, done.\n",
            "Resolving deltas: 100% (388/388), done.\n",
            "Processing ./pytorch-grad-cam\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from grad-cam==1.3.2) (4.62.3)\n",
            "Requirement already satisfied: ttach>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from grad-cam==1.3.2) (0.0.3)\n",
            "Collecting opencv-python>=4.5torch>=1.4\n",
            "  Downloading opencv_python-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.3 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from grad-cam==1.3.2) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.5torch>=1.4->grad-cam==1.3.2) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->grad-cam==1.3.2) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->grad-cam==1.3.2) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision>=0.5->grad-cam==1.3.2) (3.10.0.2)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.3.2-py3-none-any.whl size=20658 sha256=56bf7f810596cc6892cd03151737423aa8bb42cf1bb37e647bf8230223c36b91\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/cb/7e/31a3553b353ebe761ab45b4267c016ff23c49ba5acd801a813\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: opencv-python, grad-cam\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed grad-cam-1.3.2 opencv-python-4.5.4.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vhXncVRZOzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f75ebe-497e-405e-a903-f1f3fc97f43c"
      },
      "source": [
        "# Google Collab Requirements / Checks\n",
        "from google.colab.patches import cv2_imshow # Change this before running elsewhere!!\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet50\n",
        "from torchsummary import summary\n",
        "\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtRudh4lZU-H"
      },
      "source": [
        "# Load manual ms coco dataset and bounding boxes\n",
        "# Varun's Directory\n",
        "# dir_uri = '/content/gdrive/MyDrive/University of Wisconsin-Madison/2021 Fall/cs762'\n",
        "# Devesh's Directory\n",
        "dir_uri = '/content/gdrive/MyDrive'\n",
        "\n",
        "proj_dir = dir_uri + '/CS762_Deep_Learning_Project'\n",
        "df = pd.read_excel( proj_dir + '/fullBBOX.xlsx')\n",
        "\n",
        "dataset_folder = dir_uri + '/CS762_Deep_Learning_Project/datasets/Manual_MSCOCO' \n",
        "image_names = []\n",
        "for filename in os.listdir(dataset_folder):\n",
        "  image_names.append(filename)\n",
        "\n",
        "image_names.sort(key=lambda x: int(x.split('-')[0]))\n",
        "\n",
        "# Load iamge net categories\n",
        "imageNet_labels_path = dir_uri + \"/CS762_Deep_Learning_Project/datasets/imagenet_classes.txt\"\n",
        "# Read the categories\n",
        "with open(imageNet_labels_path, \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "\n",
        "# Load bbox's\n",
        "bbox_path = proj_dir + '/fullBBOX.xlsx'\n",
        "bbox_df = pd.read_excel(bbox_path)\n",
        "all_boxes = bbox_df.to_numpy()\n",
        "\n",
        "output_file = proj_dir + '/Q2/q2_output_resnet_deit.csv'\n",
        "headers = ['image_name', 'threshold', 'resnet label', 'resnet accuracy', 'resnet whole image %', 'resnet in bbox %', 'resnet outside bbox %', 'deit label', 'deit accuracy', 'deit whole image %', 'deit in bbox %', 'deit outside bbox %']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzZ-wNVcZW82"
      },
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize( (224, 224) ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def reshape_transform(tensor, height=14, width=14):\n",
        "    result = tensor[:, 1:, :].reshape(tensor.size(0),\n",
        "                                      height, width, tensor.size(2))\n",
        "\n",
        "    # Bring the channels to the first dimension,\n",
        "    # like in CNNs.\n",
        "    result = result.transpose(2, 3).transpose(1, 2)\n",
        "    return result\n",
        "\n",
        "\n",
        "# bbox given as one row from our fullBBox.xlsx file\n",
        "def eval_metric_percent_above(grayscale_cam, bbox, threshold):\n",
        "\n",
        "    # find area of bbox\n",
        "    topLeft_w = int(bbox[2])\n",
        "    topLeft_h = int(bbox[3])\n",
        "    botRight_w = int(bbox[6])\n",
        "    botRight_h = int(bbox[7])\n",
        "    width_bbox = abs(botRight_w - topLeft_w)\n",
        "    height_bbox = abs(topLeft_h - botRight_h)\n",
        "    area = width_bbox * height_bbox\n",
        "\n",
        "    # percent above threshold whole image\n",
        "    above_threshold = (grayscale_cam > threshold)\n",
        "    count_above_threshold = above_threshold.sum()\n",
        "    total_count = grayscale_cam.shape[0] * grayscale_cam.shape[1]\n",
        "    percent_above_threshold_whole_image = (count_above_threshold / total_count) * 100\n",
        "\n",
        "    # percent above threshold in bbox\n",
        "    bbox_grayscale_cam = grayscale_cam[topLeft_h:botRight_h, topLeft_w:botRight_w]\n",
        "    bbox_above_threshold = (bbox_grayscale_cam > threshold)\n",
        "    bbox_count_above_threshold = bbox_above_threshold.sum()\n",
        "    bbox_total_count = bbox_grayscale_cam.shape[0] * bbox_grayscale_cam.shape[1]\n",
        "    percent_above_threshold_in_bbox = (bbox_count_above_threshold / bbox_total_count) * 100\n",
        "\n",
        "    # percent above threshold outside bbox\n",
        "    outside_bbox_cam = copy.deepcopy(grayscale_cam)\n",
        "    outside_bbox_cam[topLeft_h:botRight_h, topLeft_w:botRight_w] = np.zeros((height_bbox, width_bbox))\n",
        "    outside_bbox_above_threshold = (outside_bbox_cam > threshold)\n",
        "    outside_bbox_count_above_threshold = outside_bbox_above_threshold.sum()\n",
        "    outside_bbox_total_count = total_count - bbox_total_count\n",
        "    percent_above_threshold_outside_bbox = (outside_bbox_count_above_threshold / outside_bbox_total_count) * 100\n",
        "\n",
        "    # return\n",
        "    return percent_above_threshold_whole_image, percent_above_threshold_in_bbox, percent_above_threshold_outside_bbox\n",
        "\n",
        "\n",
        "def resizeBbox(orig_bbox, orig_img_size, new_img_size):\n",
        "    orig_h = orig_img_size[0]\n",
        "    orig_w = orig_img_size[1]\n",
        "    new_h = new_img_size[0]\n",
        "    new_w = new_img_size[1]\n",
        "\n",
        "    h_ratio = new_h / orig_h\n",
        "    w_ratio = new_w / orig_w\n",
        "\n",
        "    new_bbox = copy.deepcopy(orig_bbox)\n",
        "    new_bbox[2] = orig_bbox[2] * w_ratio\n",
        "    new_bbox[3] = orig_bbox[3] * h_ratio\n",
        "    new_bbox[4] = orig_bbox[4] * w_ratio\n",
        "    new_bbox[5] = orig_bbox[5] * h_ratio\n",
        "    new_bbox[6] = orig_bbox[6] * w_ratio\n",
        "    new_bbox[7] = orig_bbox[7] * h_ratio\n",
        "    new_bbox[8] = orig_bbox[8] * w_ratio\n",
        "    new_bbox[9] = orig_bbox[9] * h_ratio\n",
        "\n",
        "    return new_bbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQVqAqjp315F"
      },
      "source": [
        "preprocess_eval = transforms.Compose([\n",
        "    transforms.Resize( (224, 224) ),\n",
        "])\n",
        "\n",
        "def show_cam_on_image_updated(img: np.ndarray,\n",
        "                      mask: np.ndarray,\n",
        "                      use_rgb: bool = False,\n",
        "                      colormap: int = cv2.COLORMAP_JET) -> np.ndarray:\n",
        "    \"\"\" This function overlays the cam mask on the image as an heatmap.\n",
        "    By default the heatmap is in BGR format.\n",
        "    :param img: The base image in RGB or BGR format.\n",
        "    :param mask: The cam mask.\n",
        "    :param use_rgb: Whether to use an RGB or BGR heatmap, this should be set to True if 'img' is in RGB format.\n",
        "    :param colormap: The OpenCV colormap to be used.\n",
        "    :returns: The default image with the cam overlay.\n",
        "    \"\"\"\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), colormap)\n",
        "    if use_rgb:\n",
        "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "\n",
        "    if np.max(img) > 1:\n",
        "        raise Exception(\n",
        "            \"The input image should np.float32 in the range [0, 1]\")\n",
        "\n",
        "    cam = heatmap + img\n",
        "    cam = cam / np.max(cam)\n",
        "    return heatmap, np.uint8(255 * cam)\n",
        "\n",
        "\n",
        "def visualize_eval_metric(rgb_image, grayscale_cam, heatmap, bbox, threshold):\n",
        "    red_color = (0, 0, 255)\n",
        "    thickness = 2\n",
        "    start_point = (int(bbox[2]), int(bbox[3]))\n",
        "    end_point = (int(bbox[6]), int(bbox[7]))\n",
        "\n",
        "    above_threshold = (grayscale_cam > threshold)\n",
        "\n",
        "    for i in range(grayscale_cam.shape[0]):\n",
        "      for j in range(grayscale_cam.shape[1]):\n",
        "        if(above_threshold[i, j] == False):\n",
        "          heatmap[i,j,0] = 0\n",
        "          heatmap[i,j,1] = 0\n",
        "          heatmap[i,j,2] = 0\n",
        "\n",
        "    cam = heatmap + rgb_image\n",
        "    cam = cam / np.max(cam)\n",
        "    cam = np.uint8(255 * cam)\n",
        "    cam = cv2.rectangle(cam, start_point, end_point, red_color, thickness)\n",
        "    return cam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_cam_on_image_updated_blank(img: np.ndarray,\n",
        "                      mask: np.ndarray,\n",
        "                      use_rgb: bool = False,\n",
        "                      colormap: int = cv2.COLORMAP_JET) -> np.ndarray:\n",
        "    \"\"\" This function overlays the cam mask on the image as an heatmap.\n",
        "    By default the heatmap is in BGR format.\n",
        "    :param img: The base image in RGB or BGR format.\n",
        "    :param mask: The cam mask.\n",
        "    :param use_rgb: Whether to use an RGB or BGR heatmap, this should be set to True if 'img' is in RGB format.\n",
        "    :param colormap: The OpenCV colormap to be used.\n",
        "    :returns: The default image with the cam overlay.\n",
        "    \"\"\"\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), colormap)\n",
        "    if use_rgb:\n",
        "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "\n",
        "    if np.max(img) > 1:\n",
        "        raise Exception(\n",
        "            \"The input image should np.float32 in the range [0, 1]\")\n",
        "\n",
        "    img[(img[:,:,0]<300) & (img[:,:,1]<300) & (img[:,:,2]<300)] = [1,1,1]\n",
        "    cam = heatmap + img\n",
        "    cam = cam / np.max(cam)\n",
        "    return heatmap, np.uint8(255 * cam)"
      ],
      "metadata": {
        "id": "d1GN8T9POKRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "5d60e0c975ea4b5f9fc977ecf37762ed",
            "562776ececa94061b51183ae5ae50e26",
            "f7c656b918f34dca8c8cb544da80c79a",
            "6c584ede18a44f94986a4a7c9d6420af",
            "bef72ca4abbf4ffdba83b22e417dd15a",
            "ff266179d74d4cc2944eabcca4232c9a",
            "38d569a318714852a19bf8bea3aeefe1",
            "ec78162b14a3472ea9b0cfc9772dbad1",
            "b4470285b0b747b5999ae2234acf98df",
            "6345f865d54f4b1bac285b4317f8ad74",
            "a9bbeaf078ee43d6b63b2335d33843e3",
            "4d1ca7ed135d4e3fa993ac140aa52f38",
            "e92092e78bcf45fb8a6044ffb8436ac4",
            "4931863fbdd9470db32a29993e05dd79",
            "13ca5b9820ff4b1aa224fbe160eb733e",
            "3e39b810b4d14c3282c68e498eeddeb4",
            "cdf6986108524cf49ac993ec4108a4ea",
            "60d0ffe1a69b41b2a35d5b7d7b0e779a",
            "9837af3a2382477aa7de75d615bf7acd",
            "ac90275949ab4f8f97fe77289c58c469",
            "cf5c777282284a49923fb5edafbc71cd",
            "87ae01f200594fcba55abb1ca083d5bd"
          ]
        },
        "id": "Gye9G6bYcmPU",
        "outputId": "18521848-3777-43fe-f600-cf71df5d71d0"
      },
      "source": [
        "resnet_model = resnet50(pretrained=True)\n",
        "resnet_model.eval();\n",
        "\n",
        "deit_model = torch.hub.load('facebookresearch/deit:main',\n",
        "                          'deit_tiny_patch16_224', pretrained=True)\n",
        "deit_model.eval();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d60e0c975ea4b5f9fc977ecf37762ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/deit/archive/main.zip\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\" to /root/.cache/torch/hub/checkpoints/deit_tiny_patch16_224-a1311bcf.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d1ca7ed135d4e3fa993ac140aa52f38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/21.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JLGhFsReLy5"
      },
      "source": [
        "resnet_target_layers = [resnet_model.layer4[-1]]\n",
        "deit_target_layers = [deit_model.blocks[-1].norm1]\n",
        "\n",
        "target_category = None\n",
        "\n",
        "resnet_input_image_shape = (224, 224, 3)\n",
        "deit_input_image_shape = (224, 224, 3)\n",
        "\n",
        "threshold_options = [0.7, 0.9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M5Uzx3Mc_RM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb7b505-f01b-418f-a6e6-83adace1f3cc"
      },
      "source": [
        "output_data = []\n",
        "\n",
        "for threshold in threshold_options:\n",
        "  for i in range( len( image_names ) ):\n",
        "    # Create input\n",
        "    test_img = Image.open( dataset_folder + '/' + image_names[i] ).convert('RGB')\n",
        "    input_tensor = preprocess(test_img)\n",
        "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "    orig_bbox = all_boxes[i]\n",
        "    orig_img_shape = np.array(test_img).shape\n",
        "\n",
        "    # Create target lable\n",
        "    target_name = image_names[i].split( '-' )[1]\n",
        "    target_name = target_name.split( '.' )[0]\n",
        "\n",
        "    # Set target category\n",
        "    target_category = [index for index, class_instance in enumerate(categories) if class_instance == target_name]\n",
        "\n",
        "    # If target category is empty (ie label does not exist in image net, skip this image):\n",
        "    if ( len( target_category ) == 0 ):\n",
        "      continue\n",
        "\n",
        "    print( image_names[i] )\n",
        "\n",
        "    # RESNET\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output = resnet_model(input_batch)\n",
        "\n",
        "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "\n",
        "    # Get top category\n",
        "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "    resnet_predicted_label = categories[top5_catid[0]]\n",
        "    resnet_predicted_label_prob = top5_prob[0].item()\n",
        "\n",
        "    resnet_cam = GradCAM(model=resnet_model, target_layers=resnet_target_layers)\n",
        "    resnet_grayscale_cam = resnet_cam(input_tensor=input_batch, target_category=target_category)\n",
        "    resnet_grayscale_cam = resnet_grayscale_cam[0, :]\n",
        "    \n",
        "    # resize bbox and calculate metrics\n",
        "    new_bbox_resnet = resizeBbox(orig_bbox, (orig_img_shape[0], orig_img_shape[1]), (resnet_input_image_shape[0], resnet_input_image_shape[1]))\n",
        "    resnet_whole_img, resnet_in_bbox, resnet_out_bbox = eval_metric_percent_above(resnet_grayscale_cam, new_bbox_resnet, threshold)\n",
        "\n",
        "\n",
        "    # DEIT\n",
        "\n",
        "    # compute the predictions\n",
        "    with torch.no_grad():\n",
        "      output = deit_model(input_batch)\n",
        "\n",
        "    # and convert them into probabilities\n",
        "    scores = torch.nn.functional.softmax(output, dim=-1)[0]\n",
        "\n",
        "    # finally get the index of the prediction with highest score\n",
        "    topk_scores, topk_label = torch.topk(scores, k=5, dim=-1)\n",
        "    deit_predicted_label = categories[topk_label[0]]\n",
        "    deit_predicted_label_prob = topk_scores[0].item()\n",
        "\n",
        "    deit_cam = GradCAM(model=deit_model, target_layers=deit_target_layers, reshape_transform=reshape_transform)\n",
        "    deit_grayscale_cam = deit_cam(input_tensor=input_batch, target_category=target_category)\n",
        "    deit_grayscale_cam = deit_grayscale_cam[0, :]\n",
        "\n",
        "    # resize bbox and calculate metrics\n",
        "    new_bbox_deit = resizeBbox(orig_bbox, (orig_img_shape[0], orig_img_shape[1]), (deit_input_image_shape[0], deit_input_image_shape[1]))\n",
        "    deit_whole_img, deit_in_bbox, deit_out_bbox = eval_metric_percent_above(deit_grayscale_cam, new_bbox_deit, threshold)\n",
        "\n",
        "    output_data.append( [image_names[i], threshold, resnet_predicted_label, resnet_predicted_label_prob, resnet_whole_img, resnet_in_bbox, resnet_out_bbox, deit_predicted_label, deit_predicted_label_prob, deit_whole_img, deit_in_bbox, deit_out_bbox] )\n",
        "\n",
        "    # Delete garbage for ram\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.8709, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0648, grad_fn=<AddBackward0>)]\n",
            "51-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.7910, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9930, grad_fn=<AddBackward0>)]\n",
            "52-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(20.2493, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.7388, grad_fn=<AddBackward0>)]\n",
            "53-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.4557, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0184, grad_fn=<AddBackward0>)]\n",
            "54-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.0945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9074, grad_fn=<AddBackward0>)]\n",
            "55-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.4308, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.3042, grad_fn=<AddBackward0>)]\n",
            "56-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.9964, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2394, grad_fn=<AddBackward0>)]\n",
            "57-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.9097, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9136, grad_fn=<AddBackward0>)]\n",
            "58-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9447, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(2.5324, grad_fn=<AddBackward0>)]\n",
            "59-backpack.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.5146, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.3028, grad_fn=<AddBackward0>)]\n",
            "60-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.6481, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.8600, grad_fn=<AddBackward0>)]\n",
            "61-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.2327, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.5883, grad_fn=<AddBackward0>)]\n",
            "62-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.4884, grad_fn=<AddBackward0>)]\n",
            "63-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.9904, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2501, grad_fn=<AddBackward0>)]\n",
            "64-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.1559, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.7970, grad_fn=<AddBackward0>)]\n",
            "65-parking meter.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.0236, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4257, grad_fn=<AddBackward0>)]\n",
            "66-parking meter.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(27.9061, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.3178, grad_fn=<AddBackward0>)]\n",
            "67-parking meter.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.9491, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5806, grad_fn=<AddBackward0>)]\n",
            "68-parking meter.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.5151, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2023, grad_fn=<AddBackward0>)]\n",
            "69-parking meter.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.6251, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.4856, grad_fn=<AddBackward0>)]\n",
            "85-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5505, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.9668, grad_fn=<AddBackward0>)]\n",
            "86-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.7550, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0761, grad_fn=<AddBackward0>)]\n",
            "87-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.8692, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.1165, grad_fn=<AddBackward0>)]\n",
            "88-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(16.4945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.3757, grad_fn=<AddBackward0>)]\n",
            "89-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.9281, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9060, grad_fn=<AddBackward0>)]\n",
            "90-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.0727, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3159, grad_fn=<AddBackward0>)]\n",
            "91-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.1906, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9205, grad_fn=<AddBackward0>)]\n",
            "92-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.4846, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.2691, grad_fn=<AddBackward0>)]\n",
            "93-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.6239, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.8853, grad_fn=<AddBackward0>)]\n",
            "94-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.2879, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.0607, grad_fn=<AddBackward0>)]\n",
            "95-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.1745, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4130, grad_fn=<AddBackward0>)]\n",
            "96-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2133, grad_fn=<AddBackward0>)]\n",
            "97-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.4512, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3736, grad_fn=<AddBackward0>)]\n",
            "98-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2442, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5152, grad_fn=<AddBackward0>)]\n",
            "99-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.2510, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.8365, grad_fn=<AddBackward0>)]\n",
            "50-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.8709, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0648, grad_fn=<AddBackward0>)]\n",
            "51-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.7910, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9930, grad_fn=<AddBackward0>)]\n",
            "52-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(20.2493, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.7388, grad_fn=<AddBackward0>)]\n",
            "53-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.4557, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0184, grad_fn=<AddBackward0>)]\n",
            "54-zebra.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.0945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9074, grad_fn=<AddBackward0>)]\n",
            "55-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.4308, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.3042, grad_fn=<AddBackward0>)]\n",
            "56-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.9964, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2394, grad_fn=<AddBackward0>)]\n",
            "57-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.9097, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9136, grad_fn=<AddBackward0>)]\n",
            "58-backpack.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9447, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(2.5324, grad_fn=<AddBackward0>)]\n",
            "59-backpack.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.5146, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.3028, grad_fn=<AddBackward0>)]\n",
            "60-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.6481, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.8600, grad_fn=<AddBackward0>)]\n",
            "61-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.2327, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.5883, grad_fn=<AddBackward0>)]\n",
            "62-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.4884, grad_fn=<AddBackward0>)]\n",
            "63-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.9904, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2501, grad_fn=<AddBackward0>)]\n",
            "64-umbrella.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.1559, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.7970, grad_fn=<AddBackward0>)]\n",
            "65-parking meter.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.0236, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4257, grad_fn=<AddBackward0>)]\n",
            "66-parking meter.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(27.9061, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.3178, grad_fn=<AddBackward0>)]\n",
            "67-parking meter.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.9491, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5806, grad_fn=<AddBackward0>)]\n",
            "68-parking meter.jpeg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.5151, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2023, grad_fn=<AddBackward0>)]\n",
            "69-parking meter.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.6251, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.4856, grad_fn=<AddBackward0>)]\n",
            "85-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5505, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.9668, grad_fn=<AddBackward0>)]\n",
            "86-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.7550, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0761, grad_fn=<AddBackward0>)]\n",
            "87-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.8692, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.1165, grad_fn=<AddBackward0>)]\n",
            "88-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(16.4945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.3757, grad_fn=<AddBackward0>)]\n",
            "89-mouse.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.9281, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9060, grad_fn=<AddBackward0>)]\n",
            "90-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.0727, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3159, grad_fn=<AddBackward0>)]\n",
            "91-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.1906, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9205, grad_fn=<AddBackward0>)]\n",
            "92-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.4846, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.2691, grad_fn=<AddBackward0>)]\n",
            "93-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.6239, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.8853, grad_fn=<AddBackward0>)]\n",
            "94-vase.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.2879, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.0607, grad_fn=<AddBackward0>)]\n",
            "95-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.1745, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4130, grad_fn=<AddBackward0>)]\n",
            "96-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2133, grad_fn=<AddBackward0>)]\n",
            "97-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.4512, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3736, grad_fn=<AddBackward0>)]\n",
            "98-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2442, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5152, grad_fn=<AddBackward0>)]\n",
            "99-cup.jpg\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.2510, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.8365, grad_fn=<AddBackward0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDgBUlnOxPAb"
      },
      "source": [
        "df = pd.DataFrame (output_data, columns=headers)\n",
        "df.to_csv(output_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPP9v4vq1ymq"
      },
      "source": [
        "output_images_dir = proj_dir + '/Q2/output_images/'\n",
        "images_to_visualize = [50, 56, 60, 63, 67]\n",
        "threshold = 0.7\n",
        "generate_vis_analysis = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiBAMlXC3dN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c4da2b-1b34-4233-dc3a-a18b3bc6aafd"
      },
      "source": [
        "if(generate_vis_analysis):\n",
        "  for i in range(0, len(image_names)):\n",
        "    # Create input\n",
        "    test_img = Image.open( dataset_folder + '/' + image_names[i] ).convert('RGB')\n",
        "    resnet_path = output_images_dir + image_names[i] + '_resnet_whole'\n",
        "    resnet_path_t = output_images_dir + image_names[i] + '_resnet_thres'\n",
        "    deit_path = output_images_dir + image_names[i] + '_deit_whole'\n",
        "    deit_path_t = output_images_dir + image_names[i] + '_deit_thres'\n",
        "    input_tensor = preprocess(test_img)\n",
        "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "    orig_bbox = all_boxes[i]\n",
        "    orig_img_shape = np.array(test_img).shape\n",
        "\n",
        "    rgb_image = np.array(preprocess_eval(test_img)).astype(np.float32)\n",
        "    rgb_image = rgb_image/255\n",
        "\n",
        "    # Create target lable\n",
        "    target_name = image_names[i].split( '-' )[1]\n",
        "    target_name = target_name.split( '.' )[0]\n",
        "\n",
        "    # Set target category\n",
        "    target_category = [index for index, class_instance in enumerate(categories) if class_instance == target_name]\n",
        "\n",
        "    # If target category is empty (ie label does not exist in image net, skip this image):\n",
        "    if ( len( target_category ) == 0 ):\n",
        "      continue\n",
        "\n",
        "    # Resnet\n",
        "    resnet_cam = GradCAM(model=resnet_model, target_layers=resnet_target_layers)\n",
        "    resnet_grayscale_cam = resnet_cam(input_tensor=input_batch, target_category=target_category)\n",
        "    resnet_grayscale_cam = resnet_grayscale_cam[0, :]\n",
        "\n",
        "    resnet_heatmap, resnet_visualization = show_cam_on_image_updated(rgb_image, resnet_grayscale_cam, use_rgb=False)\n",
        "    cv2.imwrite(resnet_path, resnet_visualization)\n",
        "\n",
        "    new_bbox_resnet = resizeBbox(orig_bbox, (orig_img_shape[0], orig_img_shape[1]), (resnet_input_image_shape[0], resnet_input_image_shape[1]))\n",
        "    resnet_visualized_cam_threshold = visualize_eval_metric(rgb_image, resnet_grayscale_cam, resnet_heatmap, new_bbox_resnet, threshold)\n",
        "    cv2.imwrite(resnet_path_t, resnet_visualized_cam_threshold)\n",
        "\n",
        "    # DEIT\n",
        "    deit_cam = GradCAM(model=deit_model, target_layers=deit_target_layers, reshape_transform=reshape_transform)\n",
        "    deit_grayscale_cam = deit_cam(input_tensor=input_batch, target_category=target_category)\n",
        "    deit_grayscale_cam = deit_grayscale_cam[0, :]\n",
        "\n",
        "    deit_heatmap, deit_visualization = show_cam_on_image_updated(rgb_image, deit_grayscale_cam, use_rgb=False)\n",
        "    cv2.imwrite(deit_path, deit_visualization)\n",
        "\n",
        "    new_bbox_deit = resizeBbox(orig_bbox, (orig_img_shape[0], orig_img_shape[1]), (deit_input_image_shape[0], deit_input_image_shape[1]))\n",
        "    deit_visualized_cam_threshold = visualize_eval_metric(rgb_image, deit_grayscale_cam, deit_heatmap, new_bbox_deit, threshold)\n",
        "    cv2.imwrite(deit_path_t, deit_visualized_cam_threshold)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.8709, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0648, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.7910, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9930, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(20.2493, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.7388, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.4557, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0184, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.0945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9074, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.4308, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.3042, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.9964, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2394, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.9097, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9136, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9447, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(2.5324, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.5146, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.3028, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.6481, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.8600, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.2327, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.5883, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.4884, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.9904, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2501, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.1559, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.7970, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.0236, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4257, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(27.9061, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.3178, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.9491, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5806, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.5151, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2023, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.6251, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.4856, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5505, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.9668, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.7550, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0761, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.8692, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.1165, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(16.4945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.3757, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.9281, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9060, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.0727, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3159, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.1906, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9205, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.4846, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.2691, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.6239, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.8853, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.2879, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.0607, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.1745, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4130, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2133, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.4512, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3736, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2442, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5152, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.2510, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.8365, grad_fn=<AddBackward0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_images_dir = proj_dir + '/Q2/output_images_blank_background/'\n",
        "generate_vis_analysis = True\n",
        "\n",
        "if(generate_vis_analysis):\n",
        "  for i in range(0, len(image_names)):\n",
        "    # Create input\n",
        "    test_img = Image.open( dataset_folder + '/' + image_names[i] ).convert('RGB')\n",
        "    resnet_path = output_images_dir + 'resnet/' + image_names[i].split('.')[0] + '_resnet_whole.' + image_names[i].split('.')[1]\n",
        "    deit_path = output_images_dir + 'deit/' + image_names[i].split('.')[0] + '_deit_whole.' + image_names[i].split('.')[1]\n",
        "\n",
        "    input_tensor = preprocess(test_img)\n",
        "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "    orig_bbox = all_boxes[i]\n",
        "    orig_img_shape = np.array(test_img).shape\n",
        "\n",
        "    rgb_image = np.array(preprocess_eval(test_img)).astype(np.float32)\n",
        "    rgb_image = rgb_image/255\n",
        "\n",
        "    # Create target lable\n",
        "    target_name = image_names[i].split( '-' )[1]\n",
        "    target_name = target_name.split( '.' )[0]\n",
        "\n",
        "    # Set target category\n",
        "    target_category = [index for index, class_instance in enumerate(categories) if class_instance == target_name]\n",
        "\n",
        "    # If target category is empty (ie label does not exist in image net, skip this image):\n",
        "    if ( len( target_category ) == 0 ):\n",
        "      continue\n",
        "\n",
        "    # Resnet\n",
        "    resnet_cam = GradCAM(model=resnet_model, target_layers=resnet_target_layers)\n",
        "    resnet_grayscale_cam = resnet_cam(input_tensor=input_batch, target_category=target_category)\n",
        "    resnet_grayscale_cam = resnet_grayscale_cam[0, :]\n",
        "\n",
        "    resnet_heatmap, resnet_visualization = show_cam_on_image_updated_blank(rgb_image, resnet_grayscale_cam, use_rgb=False)\n",
        "    cv2.imwrite(resnet_path, resnet_visualization)\n",
        "\n",
        "    # DEIT\n",
        "    deit_cam = GradCAM(model=deit_model, target_layers=deit_target_layers, reshape_transform=reshape_transform)\n",
        "    deit_grayscale_cam = deit_cam(input_tensor=input_batch, target_category=target_category)\n",
        "    deit_grayscale_cam = deit_grayscale_cam[0, :]\n",
        "\n",
        "    deit_heatmap, deit_visualization = show_cam_on_image_updated_blank(rgb_image, deit_grayscale_cam, use_rgb=False)\n",
        "    cv2.imwrite(deit_path, deit_visualization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-9JBBCoOTdh",
        "outputId": "5cd3c087-0169-454a-a7da-5ee98898643d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.8709, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0648, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.7910, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9930, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(20.2493, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.7388, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.4557, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0184, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.0945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.9074, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.4308, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.3042, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.9964, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2394, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.9097, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9136, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9447, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(2.5324, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.5146, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.3028, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.6481, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.8600, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.2327, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.5883, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.4884, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.9904, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2501, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.1559, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.7970, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.0236, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4257, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(27.9061, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.3178, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.9491, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5806, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.5151, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2023, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.6251, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.4856, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5505, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.9668, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.7550, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.0761, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(19.8692, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.1165, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(16.4945, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(6.3757, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(11.9281, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(5.9060, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.0727, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3159, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.1906, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.9205, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(17.4846, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.2691, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.6239, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.8853, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(22.2879, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(10.0607, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(15.1745, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.4130, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(13.8002, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(9.2133, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(12.4512, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.3736, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.2442, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(7.5152, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(8.2510, grad_fn=<AddBackward0>)]\n",
            "<class 'torch.Tensor'>\n",
            "The max logit value is [tensor(4.8365, grad_fn=<AddBackward0>)]\n"
          ]
        }
      ]
    }
  ]
}